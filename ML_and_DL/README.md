<p align="right">Refer to Hands-on Machine Learning with Scikit-Learn & TensorFlow Aurelien Geron</p>

## 人工智能(AI)
![AI](../PNG/AI.PNG)
- 人工智能：机器表现出来的智能
    - 机器学习：计算机程序利用经验E学习任务T，性能是P，针对任务T的性能P随着经验E不断增长(让计算机具有学习的能力)
        - 深度学习：深度神经网络
---
## 机器学习
- 机器学习
    - 擅长
        - 需要进行大量手工调整或需要拥有长串规则才能解决的问题
        - 问题复杂，传统方法难以解决
        - 环境有波动
        - 洞察复杂问题和大量数据
    - 挑战
        - 训练数据量不足
        - 没有代表性的训练数据：样本偏差
        - 低质量数据：数据清洗
        - 不相关特征：特征工程
        - 过拟合训练数据
            - 简化模型
                - 正则化：超参数
            - 收集更多训练数据
            - 减少训练数据的噪声
        - 欠拟合训练数据
            - 更强大的模型
            - 更好的特征
            - 减少限制

- 机器学习分类
    - 是否在人类监督下进行训练
        - 监督
            - 分类
            - 回归
        - 非监督
            - 聚类
            - 可视化和降维
            - 异常检测
            - 关联性规则学习
        - 半监督 
            - 深度信念网络(DBN)：受限玻尔兹曼机
        - 强化学习：`Get reward or penalty`
            - 模拟环境：`OpenAI`
            - 马尔可夫决策过程
            - Q学习
    - 是否可以动态学习
        - 批量学习：使用所有可能数据进行训练
        - 在线学习
            - 学习速率
            - 性能监测
    - 简单比较数据或在训练数据中建立预测模型
        - 基于实例学习：记忆+相似度
        - 基于模型学习

## 一个完整的机器学习项目
- 项目概述 
    - 划定问题：监督还是非监督，分类还是回归
        - (商业)目标
        - 参考性能
        - 性能指标
        - 核实假设

- 获取数据
    - 数据仓库
    - 爬虫

- 发现并可视化数据，发现规律
    - 查找关联

- 为机器学习算法准备数据
    - 数据清洗
    - 处理文本
    - 流水线

- 选择模型
    - 训练模型
        - 线性回归
            - 正规方程
            - 梯度下降
                - 批量
                - 随机
                - 小批量
            - 正则化
        - 降维：`curse of dimentionality`
            - 投影
            - 流形学习：`Manifold Learning`
    - 性能评估
        - 训练集、验证集
            - 交叉验证
            - 混淆矩阵
            - 准确率和召回率：`F1 score`
            - ROC曲线
            - 学习曲线
        - 测试集

- 微调模型
    - 网格搜索
    - 集成方法

- 给出解决方案

- 部署、监控、维护系统
    - 监控
    - 评估
    - 自动化

## 常用算法
- 监督学习
    - K近邻算法
    - 线性回归
    - 逻辑回归
    - 支持向量机
    - 朴素贝叶斯
    - 决策树和随机森林
        - 熵
    - 集成学习和随机森林
        - bagging
        - boosting
        - stacking
    - 神经网络
- 非监督
    - 聚类
        - K均值
        - 层次聚类分析
        - 期望最大值
    - 可视化和降维
        - 主成分分析(PCA)
        - t-分布邻域嵌入算法(t-SNE)
    - 关联性规则学习
        - Apriori
        - Eclat

## 深度学习
- 兴起原因
    - 大量数据
    - 计算能力
    - 改进算法
    - 接近全局最优
    - 良性循环
- 感知器
    - 神经元的逻辑运算
- 深度学习(DNN): 两个或多个隐含层的多层感知器
    - 基本训练方法
        - 反向传播
            - 预测(向前)，测量误差
            - 反向遍历每个连接的误差贡献
            - 微调连接器权值减少误差
        - 激活函数
            - logistic函数
            - 双曲正切函数
            - Relu函数
        - 隐藏层
            - 隐藏层数量：分层结构(重用神经网络)
            - 每层的神经元数量：`黑色艺术`
                - 早期停止
                - drop out
    - 进阶
        - 问题：梯度消失/爆炸
            - 初始化策略(不同的激活函数): logistic$\rightarrow$Xavier
            - 非饱和激活函数：ELU
            - 批量标准化(BN)
            - 梯度裁剪
        - 预训练
            - 无监督预训练(RBM)
            - **自编码器**
            - 在辅助任务上预训练
        - 复用预训练层：`Models Zoos`
            - 冻结较低层
            - 缓存冻结层
            - 调整、删除和替换较高层
        - 更快的优化器
            - 动量优化
            - Nesterov加速梯度
            - AdaGrad
            - RMSProp
            - **Adam优化**
        - 学习率调整
        - 正则化避免过拟合
            - 早期停止
            - L1和L2正则化
            - Dropout
            - 最大范数正则化
            - 数据增强

## 常见神经网络
- 卷积神经网络(CNN)：图像
    - 基础
        - 卷积层：`convolution`
            - 卷积核/过滤器: `padding`
            - 叠加的多个特征映射
            - 内存需求
        - 池化层：`pooling`
            - Max pooling
    - CNN架构
        - LeNet-5
        - AlexNet
        - GoogleNet
        - ResNet
    - 应用：计算机视觉

- 循环神经网络(RNN)：时间序列
    - 基本概念
        - 循环神经元
        - 记忆单元
        - 输入和输出序列
    - 训练RNN：`BPTT`
        - 训练序列分类器
        - 截断时间反向传播
            - LSTM单元
        - 生成RNN
        - 深度RNN
    - 应用
        - 自然语言处理